{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Geting text in the wild in natural images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import detectron2\n",
    "from detectron2.utils.logger import setup_logger\n",
    "setup_logger()\n",
    "\n",
    "# import some common libraries\n",
    "import numpy as np\n",
    "import os, json, cv2, random\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# import some common detectron2 utilities\n",
    "from detectron2 import model_zoo\n",
    "from detectron2.engine import DefaultPredictor\n",
    "from detectron2.config import get_cfg\n",
    "from detectron2.utils.visualizer import Visualizer\n",
    "from detectron2.data import MetadataCatalog, DatasetCatalog\n",
    "import coco_text\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are using the coco text annotations for the coco dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ct = coco_text.COCO_Text('cocotext.v2.json')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparing the dataset along with the respective image annotations of text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from detectron2.structures import BoxMode\n",
    "\n",
    "def get_coco_dict(img_dir,d):\n",
    "    dataset_dicts = []\n",
    "    if d.find('train') !=-1:\n",
    "        imgIds = ct.getImgIds(imgIds=ct.train, catIds=[('legibility','legible')])\n",
    "    elif d.find('val') != -1:\n",
    "        imgIds = ct.getImgIds(imgIds=ct.val, catIds=[('legibility','legible')])\n",
    "    for ids in imgIds:\n",
    "        record = {}\n",
    "        img = ct.loadImgs(ids)[0]\n",
    "        filename = os.path.join(img_dir, img[\"file_name\"])        \n",
    "        record[\"file_name\"] = filename\n",
    "        record[\"image_id\"] = ids\n",
    "        record[\"height\"] = img['height']\n",
    "        record[\"width\"] = img['width']\n",
    "      \n",
    "        annoIds = ct.getAnnIds(imgIds = ids)\n",
    "        annos = ct.loadAnns(annoIds)\n",
    "        objs = []\n",
    "        for anno in annos:\n",
    "            obj = {\n",
    "                \"bbox\": anno['bbox'],\n",
    "                \"bbox_mode\": BoxMode.XYWH_ABS,\n",
    "                \"category_id\": 0 if anno['language']=='english' else 1,\n",
    "            }\n",
    "            objs.append(obj)\n",
    "        record[\"annotations\"] = objs\n",
    "        dataset_dicts.append(record)\n",
    "    return dataset_dicts\n",
    "\n",
    "for d in [\"train2014\", \"val2014\"]:\n",
    "    DatasetCatalog.register(\"coco_text_\" + d, lambda d=d: get_coco_dict(\"/coco/train2014/\",d))\n",
    "    MetadataCatalog.get(\"coco_text_\" + d).set(thing_classes=[\"english\",\"others\",])\n",
    "coco_text_metadata = MetadataCatalog.get(\"coco_text_train2014\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using the Facebook detectron2 COCO Object detection model from the model zoo to retrain on text annotations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from detectron2.engine import DefaultTrainer\n",
    "\n",
    "cfg = get_cfg()\n",
    "cfg.merge_from_file(model_zoo.get_config_file(\"COCO-Detection/faster_rcnn_R_50_FPN_3x.yaml\"))\n",
    "cfg.DATASETS.TRAIN = (\"coco_text_train2014\",)\n",
    "cfg.DATASETS.TEST = (\"coco_text_val2014\",)\n",
    "cfg.DATALOADER.NUM_WORKERS = 8\n",
    "cfg.MODEL.WEIGHTS = model_zoo.get_checkpoint_url(\"COCO-Detection/faster_rcnn_R_50_FPN_3x.yaml\")\n",
    "cfg.SOLVER.IMS_PER_BATCH = 8\n",
    "cfg.SOLVER.BASE_LR = 0.00025  \n",
    "cfg.SOLVER.MAX_ITER = 30000\n",
    "cfg.SOLVER.STEPS = []\n",
    "cfg.MODEL.ROI_HEADS.BATCH_SIZE_PER_IMAGE = 512\n",
    "cfg.MODEL.ROI_HEADS.NUM_CLASSES = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.makedirs(cfg.OUTPUT_DIR, exist_ok=True)\n",
    "trainer = DefaultTrainer(cfg)\n",
    "trainer.resume_or_load(resume=True)\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext tensorboard\n",
    "%tensorboard --logdir output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cfg.MODEL.WEIGHTS = os.path.join(cfg.OUTPUT_DIR, \"model_final.pth\")  # path to the model we just trained\n",
    "cfg.MODEL.ROI_HEADS.SCORE_THRESH_TEST = 0.7   # set a custom testing threshold\n",
    "predictor = DefaultPredictor(cfg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from detectron2.utils.visualizer import ColorMode\n",
    "import skimage.io as io\n",
    "imgIds = ct.getImgIds(imgIds=ct.val, catIds=[('legibility','legible')])\n",
    "plt.figure(figsize=(20,20))\n",
    "for d in range(3):    \n",
    "    img = ct.loadImgs(imgIds[np.random.randint(0,len(imgIds))])[0]\n",
    "    im = cv2.imread('/coco/train2014/'+img['file_name'])\n",
    "    outputs = predictor(im)  \n",
    "    v = Visualizer(im[:, :, ::-1],\n",
    "                   metadata=coco_text_metadata, \n",
    "                   scale=1,\n",
    "                   instance_mode=ColorMode.IMAGE\n",
    "    )\n",
    "    out = v.draw_instance_predictions(outputs[\"instances\"].to(\"cpu\"))\n",
    "    plt.subplot(3,1,d+1)\n",
    "    plt.imshow(out.get_image()[:, :, ::-1])\n",
    "    plt.axis(\"off\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def crop_object(image, box):\n",
    "    x_top_left = int(box[0])\n",
    "    y_top_left = int(box[1])\n",
    "    x_bottom_right = int(box[2])\n",
    "    y_bottom_right = int(box[3])\n",
    "    x_center = (x_top_left + x_bottom_right) / 2\n",
    "    y_center = (y_top_left + y_bottom_right) / 2\n",
    "    \n",
    "    crop_img = image[y_top_left:y_bottom_right, x_top_left:x_bottom_right]\n",
    "    return crop_img\n",
    "\n",
    "imgIds = ct.getImgIds(imgIds=ct.val, catIds=[('legibility','legible')])\n",
    "img = ct.loadImgs(imgIds[np.random.randint(0,len(imgIds))])[0]\n",
    "image = cv2.imread('/coco/train2014/'+img['file_name'])\n",
    "outputs = predictor(image)\n",
    "boxes = outputs[\"instances\"].to('cpu').pred_boxes\n",
    "#box = list(boxes)[0].detach().cpu().numpy()\n",
    "plt.imshow(image)\n",
    "plt.axis(\"off\")\n",
    "plt.show()\n",
    "for i,box in enumerate(boxes):\n",
    "    crop_img = crop_object(image,box)\n",
    "    plt.imshow(crop_img)\n",
    "    plt.axis(\"off\")\n",
    "    plt.show()\n",
    "    cv2.imwrite(\"/scratch/ac9025/test_images/\"+img['file_name']+\"_cropped_\"+str(i)+\".png\", crop_img)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "my_env",
   "language": "python",
   "name": "my_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
